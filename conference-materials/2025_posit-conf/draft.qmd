---
title: "Death by Dropdown?<br>Engineer Insightful Shiny Apps<br>with Behavioral Science"
author: "Jeremy Winget, PhD"
date: "2025-09-17"
date-format: "MMMM D, YYYY"
execute:
  echo: true
  eval: true
format:
  revealjs:
    code-block-background: true
    highlight-style: github
    slide-number: false
    transition: fade
    auto-animate: true
    width: 1600
    height: 900
    footer: "posit::conf(2025) | jrwinget\\.com"
    title-slide-attributes:
      data-background-image: "img/posit-conf.png"
      data-background-position: "top left"
      data-background-repeat: "no-repeat"
      data-background-color: "#213d4f"
      data-background-opacity: "0.25"
      data-background-size: "45%"
      data-notes: |
        [10 seconds; smile warmly at audience]
        Good morning everyone! Let's jump right in...
---

## {.center background-color="#2c3e50"}

::: {.text-xl}
**Ever open a dashboard with 18 filters across 6 tabs...<br>
and wonder where to even begin?**
:::

:::: {.columns .center}
::: {.column width="45%" .fragment .center}
<div class="tenor-gif-embed" data-postid="596341483704119392" data-share-method="host" data-aspect-ratio="1.32447" data-width="700px"><a href="https://tenor.com/view/monkey-computer-work-bug-developer-gif-596341483704119392">Monkey Computer GIF</a>from <a href="https://tenor.com/search/monkey-gifs">Monkey GIFs</a></div><script type="text/javascript" async src="https://tenor.com/embed.js"></script>
:::

::: {.column width="45%" .fragment .center}
<div class="tenor-gif-embed" data-postid="17038619" data-share-method="host" data-aspect-ratio="1.32447" data-width="925px"><a href="https://tenor.com/view/ron-swanson-parks-and-recreation-parks-and-rec-computer-dumpster-gif-17038619">Ron Swanson Parks And Recreation GIF</a></div><script type="text/javascript" async src="https://tenor.com/embed.js"></script>
:::
::::

::: {.notes}
- [30 seconds]
- Who here has opened a dashboard with 18 filters across 6 tabs...and wondered where to even start?
- Or maybe what they were even looking at?
- I see some knowing looks
- Now imagine you're NOT a data scientist...You're an executive who needs to make a decision in the next 10 mins
- [CLICK] This might be you...frantically clicking, hoping something makes sense
- [CLICK] Or maybe you have some...bigger feelings
- The truth is...we've all probably been there...and it's never a great experience
- [end by 40 secs]
:::

## Dashboard Support Group {background-color="#2c3e50"}

:::: {.columns}
::: {.column width="50%"}
### Raise hand if you've ever: {style="color: var(--teal-light) !important;"}
- Designed a UI with 10+ filters?
- Had a user ask for "one more dropdown"?
- Built a Shiny app with more `selectInput()` than insights?
:::

::: {.column width="50%" .center .fragment}
### Welcome! You're among friends 😊 {style="color: var(--coral-light) !important;"}

*Think of our time together as a little therapy session for dropdown overload*
:::

::: {.column width="50%" style="margin-top: var(--space-8);" .fragment}
### 👋 Hi, I'm Jeremy! {style="color: #8D9CEF !important;"}

**I'm a psychologist by training, but probably not the kind you're thinking of**

*The public sees therapists, but the discipline is powered by data.*
:::

::: {.column width="50%" style="margin-top: var(--space-8);" .fragment .center}
### My Journey {style="color: #8D9CEF !important;"}

**Applied Social Psychology** → <br>
**Full Stack Engineer** → <br>
**Led Shiny teams at scale** → <br>
**Researcher / OSS Developer**
:::
::::

::: {.notes}
- [45 seconds]
- Welcome to dashboard support group! Let's do a quick check-in.
- Raise your hand if you've designed a UI with 10+ filters. Keep it up if you've gone over 20. Anyone brave enough to admit to 30?
- How about this...who's had a user ask for "just one more dropdown" when you KNEW it would break the camel's back?
- [CLICK] If you're nodding along, you're among friends. No judgment here...this is a safe space for dropdown addiction
- [CLICK] I'm Jeremy, and I'm a recovering complexity addict. I'm a psychologist by training, but probably not the kind you're thinking
- See, a lot of folks think psychology is all about couches and therapy.
- But the discipline? It's powered by data, statistics, and understanding human behavior at scale
- [CLICK] My journey took me from studying how groups make terrible decisions under pressure, to building the systems that caused that pressure, to finally figuring out how to fix them
- [end by 1:25 mins]
:::

## Core Realization {background-color="#5b6bbf"}

> A lot of dashboard failures aren't technical...
>
> They're psychological.

::: {.notes}
- 25 seconds
- After years of building dashboards that were technical masterpieces but user experience disasters, I had this realization
- A lot dashboard failures aren't because we chose the wrong chart type or database
- They fail because we forgot that humans...wonderfully irrational, predictably overwhelmed humans...need to use them
- And here's the thing: we can engineer for psychology just as precisely as we engineer for performance
- [end by 1:50 mins]
:::

## {background-image="img/ui-before1.png" background-size="contain" background-color="#2c3e50"}

::: {.text-box-overlay-dark .absolute left="-200" bottom="100" .fragment}
### Real client. Real dashboard. Real problems.

- 18 filters across 6 tabs
- Every possible data view
- Users' curiosity quickly vanished
    - And so did their visits

::: {.fragment}
**We ran telemetry for 30 days...**
:::

:::

::: {.notes}
- [45 seconds]
- This is from an actual client...details anonymized but painfully accurate
- They had built a really impressive dashboard...technically speaking
- Lots of filters...customized views...and some really cool visualizations for deep dives
- The client was proud..."users can analyze anything!"
- Except...they didn't. Initial curiosity lasted about 3 clicks before users fled like the building was on fire
- The client had spent 6 months and considerable budget on this.
- Technical debt was mounting.
- Users were finding creative workarounds like...Excel
- [CLICK] So we instrumented it with telemetry for 30 days to get a clear picture of what users were actually doing
- If you're not familiar, telemetry is a process of collecting anonymous usage data to understand what a user is clicking, how long they stay, and where they drop off
- [end by 2:35]
:::

## Telemetry Revealed the Journey {background-color="#2c3e50"}

```{r}
#| echo: false
#| fig-width: 14
#| fig-height: 7
#| fig.align: "center"

library(ggplot2)
library(dplyr)
library(tidyr)

journey <- tibble(
  stage = c(
    "Visited app URL",
    "Opened dashboard",
    "Applied ≥1 filter",
    "Returning within 1 week"
  ),
  pct   = c(95, 88, 52, 20)
)

journey |>
  mutate(stage = reorder(stage, -pct)) |>
  ggplot(aes(x = stage, y = pct)) +
  geom_col(fill = "#5FBDB0") +
  geom_text(
    aes(label = paste0(pct, "%")),
    vjust = -0.5, size = 10
  ) +
  scale_y_continuous(limits = c(0,100), expand = c(0,0)) +
  labs(
    subtitle = "1,287 sessions tracked over 30 days",
    y = "Users (%)", x = NULL
  ) +
  theme_minimal(base_size = 20) +
  theme(
    plot.title = element_text(size = 36, face = "bold"),
    plot.subtitle = element_text(size = 24),
    axis.text.x = element_text(
      size = 16,
      angle = 25,
      hjust = 1
    ),
    axis.text.y = element_text(size = 18),
    panel.grid = element_blank()
  ) +
  ylim(0, 110)
```

::: {.notes}
- [30 seconds]
- Look at this cliff dive of despair
- 95% visited the URL...great! They're interested!
- 88% actually opened it...still good!
- But only 52% managed to apply even ONE filter. One!
- And returning users? 20%. That's not adoption, that's abandonment
- This chart is behavioral science screaming "STOP DOING THIS TO PEOPLE"
- Every dropout represents a decision unmade, an insight undiscovered, a user who now thinks your data is "too complicated"
- [end by 3:05]
:::

## Enter: Behavioral Science {background-color="#5b6bbf"}

::: {.text-large}
**What is it?** The interdisciplinary study of how people make decisions<br>
(Spoiler: irrationally, yet predictably & consistently)
:::

::: { style="margin-top: var(--space-7);"}
:::: {.columns .fragment}

### Classic Example: The Paradox of Choice {style="text-align: center; color: var(--coral-light) !important;"}

::: {.column width="45%" .fragment}

::: {.text-large}
**Researchers**: Sheena Iyengar & Mark Lepper

**Setting**: Upscale grocery store sampling booth

**Design**: 24 jams vs. 6 jams display
:::
:::

::: {.column width="45%"}
::: {.r-stack}
![](img/jam-study-blur.png){.fragment width="100%" style="border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"}

![](img/jam-study.png){.fragment width="100%" style="border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);"}
:::
:::

::::
:::

::: {.fragment .center style="margin-top: 30px;"}
### **10x higher conversion with fewer options** {style="color: var(--teal-light) !important;"}
:::

::: {.notes}
- [75 seconds]
- Behavioral science studies how humans think, feel and act...often in the context of decision making
- The field itself is a blend of psychology, economics, neuroscience, and sociology...and a common theme is that people are often irrational...but in surprisingly consistent ways
- For us as developers, this is actually great news. It means user behavior is predictable and we can design for it
- [CLICK] Let me share the famous jam study that mirrors our dashboard problem perfectly
- Researchers set up a fancy grocery store display with either 24 or 6 jam varieties
- The big display attracted browsers...60% stopped to look versus 40% for the small display
- [CLICK] But here's the kicker...only 3% bought jam after seeing 24 options, while 30% bought after seeing just 6
- [CLICK] That's a 10x conversion difference!
- More choice attracted attention but paralyzed action
- Sound familiar? That's exactly what our 18-filter dashboard was doing
- And here's what this means for your development workflow: every filter you add isn't just a feature...it's a cognitive tax on your users
- When we understand these psychological principles, we can predict which features will actually get used versus which ones will just add to your maintenance burden
- This isn't soft science...it's engineering intelligence that saves you from building things nobody will use
- [end by 4:20]
:::

## Applied to Dashboards {background-color="#5b6bbf"}

:::: {.columns}
::: {.column width="45%" style="margin-top: var(--space-8);"}
### Core Concepts {style="color: var(--coral-light) !important;"}

- **Cognitive Load**
    - Too many choices overwhelm users' mental capacity
- **Progressive Disclosure**
    - Reveal complexity gradually as users need it
- **Framing Effects**
    - Same data can tell completely different stories
- **Choice Architecture**
    - Guide decisions without restricting options
:::

::: {.column width="45%" .fragment style="margin-top: var(--space-8);"}
### Dashboard Examples {style="color: var(--teal-light) !important;"}

- **Cognitive Load**
    - Start with 3 key filters, hide 15 advanced ones
- **Progressive Disclosure**
    - Show summary → detailed dive → comparisons
- **Framing Effects**
    - "Revenue up 15%" vs "Revenue missed by 5%"
- **Choice Architecture**
    - Smart defaults, logical grouping, visual hierarchy
:::
::::

::: {.notes}
- [55 seconds]
- Now the paradox of choice is just one of many behavioral science concepts that directly apply to dashboards
- But the cool thing is that these aren't abstract theories...they're engineering principles
- Cognitive Load...Your users' brains have RAM limits. Every filter costs processing power. And unlike computer RAM, you can't just add more
- Progressive Disclosure...Nobody reads the manual. Show the basics, then reveal complexity as needed. Think of it like lazy loading for human cognition
- Framing Effects..."Revenue up 15%" versus "Missed target by 5%"...same data, vastly different user reactions. Your PM sees success, your CFO sees failure
- Choice Architecture...You're not limiting options, you're creating a path through them. Like good API design...guide the happy path
- [CLICK] In practice, this means starting with 3 filters not 18, showing summaries before details, and using smart defaults
- For Shiny developers specifically, this means using updateSelectInput() to dynamically adjust options based on user behavior, not showing everything upfront
- It means conditional panels that appear when needed, not cluttering the initial view
- And it means your reactive expressions should anticipate common user paths, pre-computing likely next steps
- This is engineering the experience as carefully as the backend
- [end by 5:15]
:::

## The Solution: Your Dashboard Journey {background-color="#2c3e50"}

:::: {.columns}
::: {.column width="30%"}
### Think of it like a road trip {style="color: var(--coral-light) !important;"}

📍 **Interpret** where you're going<br>
⚠️ **Notice** the warning lights<br>
🌦️ **Anticipate** weather changes<br>
🗺️ **Structure** the best route<br>
✅ **Validate** safe arrival

![](img/vw-bus.jpg){.r-stretch}
:::

::: {.column width="70%" .fragment}
### The BID Framework {style="color: #8D9CEF !important;"}

📍 **Interpret** user needs<br>
⚠️ **Notice** friction points<br>
🌦️ **Anticipate** cognitive biases<br>
🗺️ **Structure** information flow<br>
✅ **Validate** understanding

![](img/bid-framework.png){style="width: 80%; box-shadow: none !important; margin-left: 20%"}
:::
::::

::: {.notes}
- [45 seconds]
- Building great dashboards is like planning a road trip
- You need to know where you're going, watch for hazards, and make sure everyone arrives safely
- [CLICK] Enter the BID framework...your behavioral science GPS
- Five stages that prevent those dashboard disasters we've all experienced
- Here's what's powerful about this approach...it's not another design philosophy or abstract UX theory
- It's a concrete, implementable framework based on decades of research
- Each stage builds on the previous one, creating a feedback loop that continuously improves your dashboard
- Best part? I've packaged it all into an R package that does the heavy lifting for you
- This isn't another UI library or component framework...it's a thinking tool that helps you make better design decisions
- [end by 6:00]
:::

## What is {bidux}? {background-color="#2c3e50"}

:::: {.columns}
::: {.column width="45%" .text-large}
### An R package that: {style="color: var(--teal-light) !important;"}

- ✅ Works with ANY Shiny dashboard
- ✅ Analyzes telemetry OR works without
- ✅ Auto-suggests behavioral science improvements
- ✅ Custom parameter overrides
:::

::: {.column width="45%"}
:::

::: {.column width="45%" style="margin-top: 150px;"}
:::

::: {.column width="45%" .fragment style="margin-top: 150px;"}
### *Your behavioral scientist in the console* {style="text-align: center !important; color: #8D9CEF !important;"}
:::
::::

::: {.notes}
- [45 seconds]
- And bidux is that R package...designed specifically for our workflow as Shiny developers
- Works with ANY Shiny dashboard you've already built...no need to refactor or start over
- It can analyze telemetry if you have it, providing data-driven insights about actual user behavior
- But...it also works without telemetry, using established behavioral principles
- Auto-suggests improvements based on behavioral principles...and I mean specific suggestions like "replace this selectInput with radioButtons" or "group these filters using bslib::accordion"
- [CLICK] Think of it as a behavioral scientist in your console...one that's always available, never judges, and doesn't charge by the hour
- It translates the science into practical suggestions like "use bslib::accordion here" or "reduce these 8 filters to 3"
- It's not just about better UX...it's about reducing technical debt...improving maintainability...and building dashboards that support our users
- [end by 6:45]
:::

## INTERPRET: Start with Why {background-color="#5b6bbf"}

```{r}
#| code-line-numbers: "3|4|5-10|11-18"
#| output-location: fragment

library(bidux)

interpret_stage <- bid_interpret(
  central_question = "Which markets are driving performance?",
  data_story = list(
    hook = "Q4 revenue hit record high, but satisfaction dipped",
    context = "After aggressive marketing across all regions",
    tension = "West region satisfaction fell 10 points",
    resolution = "Focus retention efforts on underperforming regions"
  ),
  user_personas = list(
    list(
      name = "Product Manager",
      goals = "Monitor weekly KPIs",
      pain_points = "Too many filters to find important insights",
      technical_level = "Moderate"
    )
  )
)
```

::: {.notes}
- [75 seconds]
- First stage: Interpret user needs.
- What question does this dashboard answer? And I mean specifically
- [CLICK] The central question drives everything.
- If you can't state it in one sentence...users won't find it in a bunch of dropdowns
- This is where most dashboards fail...we build for "everything" instead of "the right thing"
- [CLICK] The data story creates helps create narrative structure for this
- Humans are hardwired for stories, not pivot tables
- Hook, context, tension, resolution...same structure Hollywood uses, same structure your brain expects
- [CLICK] User personas ground us in reality.
- That Product Manager isn't you...they don't think in SQL queries...They think in business outcomes.
- So the dashboard needs to bridge that gap
- [CLICK] Look at that output...the package validates your inputs and provides feedback if anything is missing
    - Which could potentially indicate a good time to check in with your stakeholders if you can't answer these questions
- Now here's why this matters for your daily work
- Every filter without clear purpose multiplies cognitive load...not just for the user...but for you as the developer as well
- At it's core, this is about engineering efficiency
- Clear purpose means less code to write...faster queries to run...and clearer testing metrics
    - Which translates to less time spent debugging and more time delivering value
- bid_interpret packages this information into an object that feeds into later stages...maintaining context throughout the analysis
- Think of it as requirements engineering that actually connects to user psychology
- [end by 8:00]
:::

## NOTICE: Find the Core Problems {background-color="#5b6bbf"}

:::: {.columns}
::: {.column width="40%"}
```{r}
#| echo: false
#| fig-width: 6
#| fig-height: 8

filters <- tibble::tibble(
  filter = factor(
    paste("Filter", 1:18),
    levels = rev(paste("Filter", 1:18))
  ),
  pct = c(
    33.8, 21.4, 13.6, 7.8, 4.9, 3.9, 2.9, 2.4, 1.8,
    1.4, 1.2, 1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4
  )
)

ggplot(filters, aes(x = 1, y = filter, fill = pct)) +
  geom_tile(color = "white", size = 1) +
  geom_text(
    aes(label = paste0(pct, "%")),
    size = 5, fontface = "bold",
    color = ifelse(filters$pct > 40, "white", "black")
  ) +
  scale_fill_gradient2(
    low = "#FCE788", mid = "#FCA311", high = "#D7263D",
    midpoint = 40, guide = "none"
  ) +
  labs(
    title = "Actual Filter Usage",
    subtitle = "14 of 18 filters show little use",
    x = "",
    y = ""
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_blank(),
    axis.ticks = element_blank(),
    panel.grid = element_blank(),
    plot.title = element_text(size = 20, face = "bold"),
    plot.subtitle = element_text(size = 16, color = "#666")
  )
```
:::

::: {.column width="60%" .fragment}
```{r}
notice_stage <- bid_notice(
  previous_stage = interpret_stage,
  problem = "Users are struggling to find key insights",
  evidence = "Telemetry shows over 75% of filters are rarely used"
)
```
:::
::::

::: {.notes}
- [60 seconds]
- When we don't plan for psychology...we actually end up BUILDING critical friction points into our dashboards
- If we go back to that opening example I showed you...here's what the filter usage looked like
- 14 them basically unused, and 4 virtually ignored.
- This is essentially their technical debt visualized
- Each unused filter is maintenance overhead with zero ROI
- Database queries running for nothing
- UI complexity slowing renders
- Future feature requests will compound this mess...you know how it goes, "just add it next to the other filters"
- That's why the Notice stage focuses on finding these friction points systematically
- [CLICK] The package auto-suggests relevant behavioral theories with confidence scores
- Here, 90% confidence it's Cognitive Load Theory...too many choices paralyzing users
- But it might also suggest Choice Overload, Analysis Paralysis, or Decision Fatigue
- Each theory comes with specific, implementable solutions
- This transforms vague complaints like "it's confusing" into specific engineering problems
- "Confusing" becomes "cognitive load exceeds working memory capacity"...now you can fix that
- The package links each theory to specific Shiny components and patterns that address it
- You're not guessing what to fix anymore...you're addressing identified psychological barriers with targeted code changes
- [end by 9:00]
:::

## ANTICIPATE: Guard Against Biases {background-color="#5b6bbf"}

:::: {.r-stack}
::: {.fragment .fade-in-then-out}
```{r}
anticipate_stage <- bid_anticipate(previous_stage = notice_stage)
```
:::

::: {.fragment .fade-in-then-out}

```{r}
# Auto-generates bias mitigations
anticipate_stage$bias_mitigations
```
:::

![](img/ui-gain-frame.png){.fragment auto-animate=true}

![](img/ui-loss-frame.png){.fragment auto-animate=true}

::: {.text-box-overlay-dark .fragment .fade-up}
**Same Data, Different Story**
:::
::::

::: {.notes}
- [45 seconds]
- Stage three: Anticipate how biases affect interpretation
- This is where behavioral science gets really practical for dashboards
- [CLICK] The package auto-generates bias mitigations based on your specific dashboard context and user personas
- [CLICK] Look at the specific suggestions...anchoring, framing, confirmation bias
- These aren't abstract concepts...they're bugs in human cognition that affect every user
- [CLICK] Same dashboard, gain framing..."We're making progress!" Optimistic, forward-looking
- [CLICK] Loss framing..."We're behind target!" Creates urgency, drives action
- Same data, completely different psychological impact
- Marketing sees growth opportunities, Finance sees risk exposure...both are right, both need different framing
- bidux helps you present both perspectives fairly, or choose the right frame for your audience
- It also suggests things like reference lines for anchoring, confidence intervals to combat overconfidence, and alternative views to fight confirmation bias
- This is proactive debugging for human psychology
- [end by 9:45]
:::

## STRUCTURE: Progressive Disclosure {background-color="#5b6bbf"}

:::: {.r-stack}
::: {.fragment .fade-in-then-out}
```{r}
structure_stage <- bid_structure(previous_stage = anticipate_stage)
```
:::

::: {.fragment .fade-in}

```{r}
# Provides suggestions how how to implement
str(structure_stage$suggestions[[1]])
```
:::

::: {.fragment .fade-left style="width: 70%"}
![](img/f-pattern-heatmap.png)
:::
::::

::: {.notes}
- [65 seconds]
- Stage four: Structure for human cognition...this is where psychology becomes architecture
- [CLICK] Look at these implementation suggestions...specific bslib and shiny components
- Not just "reduce complexity" but "use bslib::accordion for progressive disclosure" with actual code examples...(with more detailed suggestions coming soon!)
- The package knows which components map to which psychological principles
- [CLICK] See this F-pattern heatmap? This is how users tend scan dashboards...though this is culturally dependent
- Top-left gets 100% attention because that's where Western readers start
- Bottom-right might as well not exist...that's where you hide the details nobody sees
- Structure stage puts your most important insights where eyes naturally go
- It suggests information hierarchy based on your central question and user personas
- Critical KPIs go top-left, supporting details follow the F-pattern, deep-dive options progressively disclosed
- This isn't just layout...it's cognitive engineering
- You're literally structuring information to match how the human brain processes visual data
- For those building with bslib, this integrates nicely with cards() and layout_columns()
- It suggests specific breakpoints for responsive design based on cognitive load research
- And it even recommends loading sequences...what to compute first, what can be lazy-loaded, what should be pre-cached
- This isn't just about making things pretty...it's about making your reactive graph match human attention patterns
- Your most expensive computations should align with where users actually look
- [end by 10:50]
:::

## VALIDATE: Plain Language Wins {background-color="#5b6bbf"}

:::: {.r-stack}
::: {.fragment .fade-in-then-out}
```{r}
validate_stage <- bid_validate(previous_stage = structure_stage)
```
:::

::: {.fragment .fade-up}
![](img/ui-summary.png){.r-stretch}
:::
::::

::: {.notes}
- [40 seconds]
-  Final stage: Validate understanding...this is helps both you know the dashboard is working as intended...and your users know what to do next
- [couple lines about next steps for developers to test changes and iterate with the workflow]
- [CLICK] Look at that executive summary...clear, actionable, no jargon
- Revenue number, specific concern, required action...everything a decision-maker needs
- If your users can't explain what they learned in one sentence, you haven't validated understanding
- This stage generates checklists, ensures accessibility, creates those "aha" moments
- It's the difference between users saying "I looked at the dashboard" and "I know exactly what to do"
- Validation isn't the end...it feeds back to Interpret, creating continuous improvement
- Now let's take a look at the full transformation
- [end by 11:30]
:::

## The Transformation {.center background-color="#2c3e50"}

![](img/ui-before2.png){.r-stretch}

::: {.notes}
- [25 seconds]
- Here's our problem child again...18 filters, 6 tabs, information overload incarnate
- Technically perfect...every edge case handled, every possible view available
- Psychologically broken...users spent more time figuring out the interface than finding insights
- This dashboard had everything except users
- Let's see what behavioral science can do...
- [end by 12:00]
:::

## The Transformation {.center background-color="#2c3e50"}

:::: {.r-stack}

![](img/ui-after.png){.r-stretch}

::: {.text-box-overlay-dark .fragment}
| Metric                  | Before (%) | After (%) |   Δ    | Relative change |
| ----------------------- | :--------: | :-------: | :----: | :-------------- |
| Visited app URL         |     95     |     97    |   +2   | +2%             |
| Opened dashboard        |     88     |     95    |   +7   | +8%             |
| Applied ≥1 filter       |     52     |     72    |   +20  | +38%            |
| Returning within 1 week |     20     |     35    |   +15  | +75%            |

::: {.fragment .text-xl style="margin-top: 30px;"}
**More users. Deeper engagement. Stronger retention.**
:::
:::
::::

::: {.notes}
- [60 seconds]
- Same functionality...but a transformed user experience
- Clean executive summary at the top...users know immediately what matters and what to do about it
- Progressive disclosure...complexity is available but not required
- Smart defaults based on actual usage patterns...not assumptions or just making everything available
- [CLICK] Now look at these metrics...this is the ROI of behavioral science
- Filter usage up 38%...people are actually exploring data...not just abandoning ship
- Return rate up 75%...they're coming back!
    - That's the difference between a proper tool and simple shelfware
- This isn't magic...and it's not AI...it's engineering for how humans actually think
- We reduced cognitive load, aligned with mental models, and created clear information hierarchy
- [CLICK] More users, deeper engagement, stronger retention...because we removed obstacles instead of adding features
- And here's what this means for you as a developer...
- Less support tickets because users can figure it out themselves
- Fewer feature requests because they're finding what they need
- Better performance reviews because your dashboards driving decisions
- This is the difference between building features and building products people love
- [end by 13:00]
:::

## Real Impact Across Industries {background-color="#5b6bbf"}

```{r}
#| echo: false
#| fig-width: 14
#| fig-height: 7

n_deploy <- 12

metrics_long <- tibble(
  Metric = factor(
    c("Time to Insight", "Task Completion", "User Satisfaction", "Return Rate"),
    levels = c("Time to Insight", "Task Completion", "User Satisfaction", "Return Rate")
  ),
  Before = c(180, 48, 44, 22),
  After  = c(115, 62, 56, 30)
) |>
  pivot_longer(
    cols = c(Before, After),
    names_to = "State", values_to = "Value"
  ) |>
  mutate(State = factor(State, levels = c("Before", "After"))) |>
  group_by(Metric) |>
  mutate(
    BeforeValue = Value[State == "Before"][1],
    DiffPP      = ifelse(State == "After", Value - BeforeValue, NA_real_),
    MaxValue    = max(Value)
  ) |>
  ungroup()

pal <- c("Before" = "#4C78A8", "After" = "#72B7B2")

ggplot(metrics_long, aes(x = Metric, y = Value, fill = State)) +
  geom_col(position = position_dodge(width = 0.7), width = 0.7) +
  geom_text(
    aes(
      label = ifelse(
        Metric == "Time to Insight",
        paste0(Value, "s"),
        paste0(Value, "%")
      )
    ),
    position = position_dodge(width = 0.7),
    vjust = -0.5,
    size = 6,
    fontface = "bold"
  ) +
  geom_text(
    data = metrics_long |>
      filter(State == "After" & !is.na(DiffPP)) |>
      distinct(Metric, .keep_all = TRUE),
    aes(
      y = MaxValue + 20,
      label = ifelse(
        Metric == "Time to Insight",
        paste0(round(DiffPP), "s"),
        paste0("+", round(DiffPP), "%")
      )
    ),
    color = "#FF4081",
    size = 6,
    fontface = "bold"
  ) +
  scale_fill_manual(values = pal) +
  labs(
    title = paste("BID Framework Impact:", n_deploy, "Enterprise Deployments"),
    subtitle = "Average across healthcare, finance, and customer goods sectors",
    y = NULL,
    x = NULL
  ) +
  theme_minimal(base_size = 18) +
  theme(
    legend.position = "top",
    legend.title = element_blank(),
    plot.title = element_text(size = 24, face = "bold"),
    plot.subtitle = element_text(size = 14),
    axis.text = element_text(size = 14),
    panel.grid.major.x = element_blank()
  ) +
  coord_cartesian(
    ylim = c(0, max(metrics_long$MaxValue) + 20)
  )
```

::: {.notes}
- [45 seconds]
- And here are just some data to back that up
- These aren't cherry-picked results...they the 12 enterprise deployments across industries I've worked on in the last year using the BID framework
- 65 seconds faster to first insight...that's over a minute saved per user, per session
- Multiply that by hundreds of users, daily visits...you're saving hours of collective time
- Task completion up from 48% to 62%...nearly a third more decisions actually getting made
- User satisfaction up 27%...that's the difference between "I have to use this" and "I want to use this"
- Why does this work across industries?...Because human psychology doesn't change across domains
- Your finance users have the same 7±2 working memory slots as healthcare users
- They all suffer from choice overload...they all need progressive disclosure...they all have biases that affect interpretation
- The framework adapts to your domain...but the principles remain constant
- Better psychology equals better engineering equals happier developers and users
- [end by 14:45]
:::

## Simplified UX Workflows {background-color="#2c3e50"}

```{r}
#| eval: false
#| code-line-numbers: "1-2|4-5|6|7|8-10|11"

# Using telemetry data
issues <- bid_telemetry("dashboard_telemetry.sqlite")

report <- filter(issues, severity == "critical") |>
  slice_head(n = 1) |>
  bid_interpret(central_question = "Which markets are driving performance?") |>
  bid_notice_issue(issues[1, ]) |> # bridge from telemetry to BID
  bid_anticipate() |>
  bid_structure() |>
  bid_validate() |>
  bid_report(format = "markdown", include_diagrams = TRUE)
```

::: {.notes}
- [40 seconds]
- Here's the really nice part..implementing all this psychology is just a few lines of code
- [CLICK] If you have it, load telemetry with bid_telemetry...and it reads standard formats or your custom schema
- [CLICK] Here, I'm just filtering to 1 of the critical issues identified
- [CLICK] Adding a simple question the dashboard is trying to answer to contextualize everything that follows
- [CLICK] Then I use bid_notice_issues...which is a bridge function from telemetry to behavioral insights...it will auto-populate the the following stages based on the issue details
- [CLICK] Run through the remaining stages...each one building on the previous
- [CLICK] Generate a markdown report ready for your PR or documentation
- The report includes specific code suggestions, component recommendations, even CSS snippets
- It's not just analysis...it's your implementation roadmap
- This fits right into your existing workflow...use it in your development, your CI/CD, even your documentation
- [end by 15:25]
:::

## Simplified UX Workflows {background-color="#2c3e50"}

```{r}
#| eval: false
#| code-line-numbers: "1|2-10|11-14|15-17|18"

# Without telemetry data
report <- bid_interpret(
    central_question = "Which markets are driving performance?",
    data_story = list(
      hook = "Q4 revenue hit record high, but satisfaction dipped",
      context = "After aggressive marketing across all regions",
      tension = "West region satisfaction fell 10 points",
      resolution = "Focus retention efforts on underperforming regions"
    )
  ) |>
  bid_notice(
    problem = "Users are struggling to find key insights",
    evidence = "Users report not knowing where to start"
  ) |>
  bid_anticipate() |>
  bid_structure() |>
  bid_validate() |>
  bid_report(format = "text", include_diagrams = FALSE)
```

::: {.notes}
- [45 seconds]
- No telemetry? No problem...behavioral principles still apply
- [CLICK] Just define your problem manually based on user feedback or your observations
- [CLICK] Create your data story...this structures your dashboard's narrative
- [CLICK] Identify the friction...even without data...you probably know where users struggle
- [CLICK] Same five-stage pipeline...same actionable insights
- [CLICK] Generate text output perfect for tickets, documentation, or stakeholder communication
- The framework guides you whether you have tons of telemetry or just gut feelings
- It's behavioral science made practical for your daily workflow
- You can run this during development...not just after deployment
- Catch psychological issues before they become user complaints
- This is shift-left for UX...fixing problems before they're problems
- [end by 16:10]
:::

## Your Turn: Start Today {background-color="#5b6bbf"}

:::: {.columns .center}
::: {.column width="65%"}
```{r}
#| eval: false
#| code-line-numbers: "1-2|4-11|13|15|17"

install.packages("bidux")
library(bidux)

result <- bid_interpret("What do users need?") |>
  bid_notice(
    problem = "Death by dropdown",
    evidence = "User complaints"
  ) |>
  bid_anticipate() |>
  bid_structure() |>
  bid_validate()

summary(result)

bid_concepts("choice overload")

result$next_steps
```
:::

::: {.column width="35%" .fragment}
### Resources:
- 🔬 **BID Framework**: [github.com/jrwinget/bid-framework](https://github.com/jrwinget/bid-framework)
- 📚 **{bidux} Docs**: [github.com/jrwinget/bidux](https://github.com/jrwinget/bidux)
- 💬 **Community**: [github.com/jrwinget/bidux/discussions](https://github.com/jrwinget/bidux/discussions)
- 🤝 **Let's Connect!**
  - <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-bluesky" viewBox="0 0 16 16">
  <path d="M3.468 1.948C5.303 3.325 7.276 6.118 8 7.616c.725-1.498 2.698-4.29 4.532-5.668C13.855.955 16 .186 16 2.632c0 .489-.28 4.105-.444 4.692-.572 2.04-2.653 2.561-4.504 2.246 3.236.551 4.06 2.375 2.281 4.2-3.376 3.464-4.852-.87-5.23-1.98-.07-.204-.103-.3-.103-.218 0-.081-.033.014-.102.218-.379 1.11-1.855 5.444-5.231 1.98-1.778-1.825-.955-3.65 2.28-4.2-1.85.315-3.932-.205-4.503-2.246C.28 6.737 0 3.12 0 2.632 0 .186 2.145.955 3.468 1.948"/></svg> [@jrwinget](https://bsky.app/profile/jrwinget.bsky.social)
  - <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-linkedin" viewBox="0 0 16 16">
  <path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854zm4.943 12.248V6.169H2.542v7.225zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248S2.4 3.226 2.4 3.934c0 .694.521 1.248 1.327 1.248zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016l.016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225z"/></svg> [@jrwinget](https://www.linkedin.com/in/jrwinget/)
  - 🌐 [jrwinget.com](https://www.jrwinget.com)
  - 📧 [contact@jrwinget.com](mailto:contact@jrwinget.com)
:::
::::

::: {.notes}
- [45 seconds]
- You can literally start using this today
- It's available on CRAN, so installation is as simple as any other R package
- [CLICK] Install & load the library...you know the drill
- [CLICK] Run through the five stages...even with minimal input, you get valuable suggestions
- [CLICK] Use bid_concepts to explore specific behavioral principles...it's like having a psychology textbook on hand for further reading
- Want to understand choice overload? bid_concepts("choice overload") gives you theory, impact, and solutions
- [CLICK] Check the next_steps for actionable improvements...prioritized by impact
- [CLICK] I've created extensive resources...docs, discussions, examples, all designed for the R/Shiny community
- These slides will be available in the BID framework repository...and I'll be posting them on my website as well
- This community is incredible at sharing and learning together...so please connect with me on Bluesky, LinkedIn, or email
- I'd love to hear about your experiences and learn from your dashboard challenges too
- And if you implement this and see results, please share them!
- [end by 16:55]
:::

## One Thing to Remember {background-color="#2c3e50"}

:::: {.columns .center}
::: {.column width="20%" .center}
![](img/hex-bidux.png){style="box-shadow: none !important;"}
:::

::: {.column width="60%" .text-display .center}
**Dashboards don't need more features.**<br>
**They need fewer obstacles.**

::: {.fragment}
Let's do that together!
:::
:::

::: {.column width="20%" .fragment .center}
*Special thanks to the<br>
posit::conf organizers,<br>
Shiny community,<br>
and all of you for caring about your users*
:::
::::

::: {.notes}
- [35 seconds]
- If you remember just one thing from our time together today...Dashboards don't need more features, they need fewer obstacles
- Every dropdown, every filter, should bring users closer to insight, not further from it
- [CLICK] And we can do this together...the tools exist, the knowledge exists...and it's clear from all the head nods today that you all care about creating better experiences for your users
- [CLICK] Before I close, I want to offer my heartfelt thanks to the posit::conf organizers for creating this incredible space...to the broader Shiny community for pushing the boundaries of what's possible...and most importantly, to all of you...for taking the time to be here today and for caring about your users
- Now, I'd love to hear your questions and learn about the dashboard challenges you're facing!
- [end by 17:30]
:::
